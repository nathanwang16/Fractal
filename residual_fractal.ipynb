{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a790766",
   "metadata": {},
   "source": [
    "In the previous notebook we set up a HMM and forward computing process. This one will extend that idea, with a few differences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3c9482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59aa7e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using Apple M1/M2 GPU via MPS\n",
      "tensor([[1, 2, 3, 4]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"✅ Using Apple M1/M2 GPU via MPS\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"⚠️ MPS not available, falling back to CPU\")\n",
    "# experimenting with torch\n",
    "# unsqueeze function\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "c = torch.unsqueeze(x, 0)  # adds a dimension at index 0\n",
    "print(c)\n",
    "b = torch.unsqueeze(x, 1)  # adds a dimension at index 1\n",
    "print(b)\n",
    "\n",
    "       # Hidden State Ha   Hb    Hc\n",
    "transition_matrix = torch.tensor([[0.9,0.05,0.05],\n",
    "                     [0.05,0.9,0.05],\n",
    "                     [0.05,0.05,0.9]])\n",
    "\n",
    "       # emissions  # A   B    C\n",
    "emission_matrix = torch.tensor([[0.9,0.05,0.05],\n",
    "                     [0.05,0.9,0.05],\n",
    "                     [0.05,0.05,0.9]])\n",
    "\n",
    "\n",
    "pi = torch.tensor([0.3,0.4,0.3])\n",
    "\n",
    "eta = torch.tensor([0.9,0.05,0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5afe92",
   "metadata": {},
   "source": [
    "Now imagine the state and symbols are mixed into a single matrix. Design this matrix M to be able to update once every transition, that transform the current mixed state to a linear combination of it, which is the updated mixed state. Because M already inform us about the probability distribution, the update should include the symbol, and we choose one of the three msp matrix to update the probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6e5d403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.075      0.04330127]\n"
     ]
    }
   ],
   "source": [
    "def compute_msp_matrices(A: torch.Tensor, B: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Given HMM transition matrix A [N, N] and emission matrix B [N, M],\n",
    "    return a list of MSP matrices T_k, one for each observation symbol k.\n",
    "    \"\"\"\n",
    "    N, M = B.shape\n",
    "    T_list = []\n",
    "    \n",
    "    for k in range(M):  # loop over observation symbols\n",
    "        emission_col = B[:, k]                      # shape (N,)\n",
    "        T_k = A * emission_col.unsqueeze(0)         # broadcast multiply to shape (N, N)\n",
    "        T_list.append(T_k)\n",
    "    print(\"msp_matrices:\", T_list)\n",
    "    return T_list  # list of [N x N] tensors, each is T_k\n",
    "\n",
    "def generate_store_token_belief(T_list,pi:torch.tensor,eta,cycle,seed=None):\n",
    "     token = []\n",
    "     belief = []\n",
    "     store = []\n",
    "     eta = eta\n",
    "     print(\"pi:\", pi.shape[0])\n",
    "     if seed is not None:\n",
    "          torch.manual_seed(seed)\n",
    "     for _ in range(cycle):\n",
    "          dice = np.random.choice(pi.shape[0])\n",
    "          #print(\"dice:\", dice)\n",
    "          t_x = T_list[dice]\n",
    "          \n",
    "          eta = eta @ t_x\n",
    "          eta = eta / eta.sum()\n",
    "          \n",
    "          token.append(pi[dice])\n",
    "          belief.append(eta)\n",
    "          store.append(get_cartesian_from_barycentric(eta))\n",
    "     token = torch.tensor(token)\n",
    "     belief = torch.stack(belief)\n",
    "     return token,belief,store\n",
    "\n",
    "# helper function\n",
    "def get_cartesian_from_barycentric(b):\n",
    "    t = np.transpose(np.array([[0,0],[1,0],[0.5, np.sqrt(3)/2]])) # Triangle\n",
    "    return t.dot(b)\n",
    "\n",
    "print(get_cartesian_from_barycentric(eta))\n",
    "\n",
    "def plot_beliefs_on_simplex(beliefs: torch.Tensor, title=\"Belief Trajectory\"):\n",
    "    assert beliefs.shape[1] == 3, \"Only works for 3-state HMM\"\n",
    "\n",
    "    # Make triangle float32 to match beliefs\n",
    "    v0 = torch.tensor([0.0, 0.0], dtype=beliefs.dtype)\n",
    "    v1 = torch.tensor([1.0, 0.0], dtype=beliefs.dtype)\n",
    "    v2 = torch.tensor([0.5, torch.sqrt(torch.tensor(3.0, dtype=beliefs.dtype)) / 2], dtype=beliefs.dtype)\n",
    "    triangle = torch.stack([v0, v1, v2])  # [3, 2]\n",
    "    #print(\"triangle:\", triangle)\n",
    "    # Convert belief vectors to xy\n",
    "    xy_coords = beliefs @ triangle  # [T, 2]\n",
    "    #print(\"xy_coords:\", xy_coords.shape)\n",
    "    print(\"examples:\", xy_coords[0:3])\n",
    "    # Plot\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(*zip(*torch.cat([triangle, triangle[0].unsqueeze(0)], dim=0)), color='k', lw=1)\n",
    "    plt.scatter(xy_coords[:, 0], xy_coords[:, 1], s=6, c=range(len(beliefs)), cmap='viridis')\n",
    "    plt.title(title)\n",
    "    plt.axis('equal')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd0e265",
   "metadata": {},
   "source": [
    "Notes that helps you quickly know the shape of the tensors.\n",
    "\n",
    "The T_list, or the msp_matrices, are stacks of three corresponding msp matrix. \n",
    "\n",
    "Let the generation string length be x, then:\n",
    "the tokens are simply 1 dim\n",
    "the tokens are 2 dim, (3,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeb1af2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msp_matrices: [tensor([[0.8100, 0.0025, 0.0025],\n",
      "        [0.0450, 0.0450, 0.0025],\n",
      "        [0.0450, 0.0025, 0.0450]]), tensor([[0.0450, 0.0450, 0.0025],\n",
      "        [0.0025, 0.8100, 0.0025],\n",
      "        [0.0025, 0.0450, 0.0450]]), tensor([[0.0450, 0.0025, 0.0450],\n",
      "        [0.0025, 0.0450, 0.0450],\n",
      "        [0.0025, 0.0025, 0.8100]])]\n",
      "pi: 3\n",
      "token.shape: torch.Size([10000])\n",
      "example token: tensor([0.3000, 0.3000, 0.3000, 0.3000, 0.3000], device='mps:0')\n",
      "belief.shape: torch.Size([10000, 3])\n",
      "example belief: tensor([[0.9875, 0.0062, 0.0062],\n",
      "        [0.4585, 0.0285, 0.5130],\n",
      "        [0.9339, 0.0088, 0.0574],\n",
      "        [0.3150, 0.0214, 0.6636],\n",
      "        [0.0278, 0.0060, 0.9663]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "t_list = compute_msp_matrices(transition_matrix, emission_matrix)\n",
    "tokens, beliefs,store = generate_store_token_belief(t_list, pi=pi,eta=eta, cycle=10000)\n",
    "tokens = tokens.to(device)\n",
    "beliefs = beliefs.to(device)\n",
    "print(\"token.shape:\", tokens.shape)\n",
    "print(\"example token:\", tokens[0:5])\n",
    "print(\"belief.shape:\", beliefs.shape)\n",
    "print(\"example belief:\", beliefs[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbbe58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_beliefs_on_simplex(pred_tensor, title=\"Probed Beliefs from CNN Hidden States\")\n",
    "# #ploting\n",
    "# store = np.array(store)\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.plot(store[:, 0], store[:, 1], 'k.', markersize=0.5)\n",
    "# plt.axis('equal')\n",
    "# plt.title(\"HMM possible distributions\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6d1d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNHMMObserver(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=32, hidden_dim=64, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.conv1 = nn.Conv1d(in_channels=emb_dim, out_channels=hidden_dim, kernel_size=kernel_size, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=kernel_size, padding=1)\n",
    "        self.output = nn.Linear(hidden_dim, vocab_size)  # for next-token prediction\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: LongTensor of shape [B, T]\n",
    "        Returns:\n",
    "            logits: [B, T, vocab_size]\n",
    "            hidden: [B, T, hidden_dim] ← this is our \"residual stream\"\n",
    "        \"\"\"\n",
    "        x = self.embedding(x)         # [B, T, D]\n",
    "        x = x.transpose(1, 2)         # [B, D, T] for Conv1d\n",
    "        x = F.relu(self.conv1(x))     # [B, H, T]\n",
    "        #x = F.relu(self.conv2(x))     # [B, H, T]\n",
    "        x = x.transpose(1, 2)         # [B, T, H] back to standard format\n",
    "        logits = self.output(x)       # [B, T, vocab_size]\n",
    "        #print(\"example logits:\", logits[0])\n",
    "        return logits, x              # logits and internal representation\n",
    "    \n",
    "class ContinuousHMMDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokens, beliefs, seq_len):\n",
    "        self.tokens = tokens\n",
    "        self.beliefs = beliefs\n",
    "        self.seq_len = seq_len\n",
    "        self.length = len(tokens) - seq_len - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.tokens[idx : idx + self.seq_len]           # [seq_len]\n",
    "        y = self.tokens[idx + 1 : idx + self.seq_len + 1]   # [seq_len]\n",
    "        \n",
    "        b = self.beliefs[idx + 1 : idx + self.seq_len + 1]  # [seq_len, 3]\n",
    "        return x, y, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4764fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokens.long()\n",
    "ds = ContinuousHMMDataset(tokens, beliefs, seq_len=32)\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=32, shuffle=False)\n",
    "\n",
    "model = CNNHMMObserver(vocab_size=3)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(5):\n",
    "    total_loss = 0\n",
    "    for x, y, _ in dl:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        logits, _ = model(x)\n",
    "        loss = F.cross_entropy(logits.view(-1, 3), y.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        #print(\"example logits:\", logits[0])\n",
    "    print(f\"Epoch {epoch}: loss = {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e80de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reps = []\n",
    "all_beliefs = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x, _, b in dl:\n",
    "        x = x.to(device)\n",
    "        b = b.to(device)\n",
    "        _, reps = model(x)           # reps: [B, T, H]\n",
    "        all_reps.append(reps)\n",
    "        all_beliefs.append(b)\n",
    "\n",
    "reps = torch.cat(all_reps, dim=0).reshape(-1, reps.shape[-1])\n",
    "belief_targets = torch.cat(all_beliefs, dim=0).reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d93e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reps.detach().cpu().numpy()\n",
    "Y = belief_targets.detach().cpu().numpy()\n",
    "\n",
    "probe = LinearRegression()\n",
    "probe.fit(X, Y)\n",
    "Y_pred = probe.predict(X)\n",
    "\n",
    "pred_tensor = torch.tensor(Y_pred, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80899f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock1D(nn.Module):\n",
    "    def __init__(self, channels, kernel_size=3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(channels, channels, kernel_size, padding=kernel_size//2)\n",
    "        self.conv2 = nn.Conv1d(channels, channels, kernel_size, padding=kernel_size//2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.BatchNorm1d(channels)\n",
    "        self.norm2 = nn.BatchNorm1d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.norm2(x)\n",
    "        x = self.dropout(self.conv2(x))\n",
    "        return F.relu(x + residual)\n",
    "\n",
    "class ResNet1DObserver(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=32, hidden_dim=64, seq_len = 32, num_blocks=4, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.input_proj = nn.Conv1d(emb_dim, hidden_dim, kernel_size=1)\n",
    "        self.pos_emb = nn.Parameter(torch.randn(1, seq_len, emb_dim))  # [1, T, D]\n",
    "        self.blocks = nn.Sequential(*[\n",
    "            ResidualBlock1D(hidden_dim, kernel_size=kernel_size) for _ in range(num_blocks)\n",
    "        ])\n",
    "\n",
    "        self.output = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)                  # [B, T, D]\n",
    "        x = x + self.pos_emb[:, :x.size(1), :]  # add position info\n",
    "        x = x.transpose(1, 2)                  # [B, D, T]\n",
    "        x = self.input_proj(x)                 # [B, H, T]\n",
    "\n",
    "        activations = []\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            activations.append(x.transpose(1, 2))  # convert back to [B, T, H]\n",
    "\n",
    "        logits = self.output(x.transpose(1, 2))    # [B, T, vocab]\n",
    "        return logits, activations  # [B, T, vocab], [num_layers * [B, T, H]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ea38c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_beliefs_on_simplex(beliefs[:3].cpu(), title=\"Ground Truth Beliefs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c6aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokens.long()\n",
    "model = ResNet1DObserver(vocab_size=3, emb_dim=32, hidden_dim=64, num_blocks=6)\n",
    "model.to(device)\n",
    "\n",
    "ds = ContinuousHMMDataset(tokens, beliefs, seq_len=32)\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=16, shuffle=False, drop_last=True)\n",
    "\n",
    "print(\"token entropy:\", torch.unique(tokens, return_counts=True))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(2):\n",
    "    total_loss = 0\n",
    "    print(\"embedding:\", model.embedding(tokens[:1]))\n",
    "    #print(\"rep layer 0:\", activations[0][0, :5])\n",
    "    for x, y, _ in dl:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        logits, _ = model(x)\n",
    "        loss = F.cross_entropy(logits.view(-1, 3), y.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        #print(\"example logits:\", logits[0])\n",
    "    print(f\"Epoch {epoch}: loss = {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a402665",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_layer_reps = [[] for _ in range(len(model.blocks))]\n",
    "all_beliefs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, _, beliefs in dl:\n",
    "        x = x.to(device)\n",
    "        beliefs = beliefs.to(device)\n",
    "        _, layer_outputs = model(x)  # list of [B, T, H]\n",
    "\n",
    "        for i, act in enumerate(layer_outputs):\n",
    "            all_layer_reps[i].append(act)\n",
    "\n",
    "        all_beliefs.append(beliefs)\n",
    "\n",
    "# Stack and reshape\n",
    "belief_targets = torch.cat(all_beliefs, dim=0).reshape(-1, 3)  # [B*T, 3]\n",
    "\n",
    "for i, layer_list in enumerate(all_layer_reps):\n",
    "    reps = torch.cat(layer_list, dim=0).reshape(-1, layer_list[0].shape[-1])  # [B*T, H]\n",
    "\n",
    "    # Fit linear regression probe\n",
    "    X = reps.cpu().numpy()\n",
    "    Y = belief_targets.cpu().numpy()\n",
    "\n",
    "    probe = LinearRegression().fit(X, Y)\n",
    "    pred = probe.predict(X)\n",
    "    pred_tensor = torch.tensor(pred, dtype=torch.float32)\n",
    "\n",
    "    # Visualize\n",
    "    plot_beliefs_on_simplex(pred_tensor, title=f\"Probed beliefs from Layer {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a276975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f8f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class HMMDataset(Dataset):\n",
    "#     def __init__(self, tokens, beliefs, seq_len=32):\n",
    "#         self.seq_len = seq_len\n",
    "#         self.tokens = tokens\n",
    "#         self.beliefs = beliefs\n",
    "#         self.num_samples = len(tokens) - seq_len\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.num_samples\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         x = self.tokens[idx : idx + self.seq_len]\n",
    "#         y = self.tokens[idx + 1 : idx + self.seq_len + 1]\n",
    "#         b = self.beliefs[idx + 1 : idx + self.seq_len + 1]\n",
    "#         return x, y, b\n",
    "\n",
    "# class ResNet1DObserver(nn.Module):\n",
    "#     def __init__(self, vocab_size, emb_dim=32, hidden_dim=64, num_blocks=4, kernel_size=3):\n",
    "#         super().__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "#         self.input_proj = nn.Conv1d(emb_dim, hidden_dim, kernel_size=1)\n",
    "\n",
    "#         self.blocks = nn.Sequential(*[\n",
    "#             ResidualBlock1D(hidden_dim, kernel_size=kernel_size) for _ in range(num_blocks)\n",
    "#         ])\n",
    "\n",
    "#         self.output = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         \"\"\"\n",
    "#         x: [B, T] → token indices\n",
    "#         returns: logits [B, T, vocab_size], and hidden features [B, T, hidden_dim]\n",
    "#         \"\"\"\n",
    "#         x = self.embedding(x)                  # [B, T, D]\n",
    "#         x = x.transpose(1, 2)                  # [B, D, T]\n",
    "#         x = self.input_proj(x)                 # [B, H, T]\n",
    "#         x = self.blocks(x)                     # [B, H, T]\n",
    "#         x = x.transpose(1, 2)                  # [B, T, H]\n",
    "#         logits = self.output(x)                # [B, T, vocab_size]\n",
    "#         return logits, x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepseek",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
